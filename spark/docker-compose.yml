version: '3'
services:
  spark-master:
    image: bde2020/spark-master:3.2.0-hadoop3.2
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    volumes:
      - ./driver:/spark/jars/driver/
    #command: ./spark/bin/pyspark --packages com.datastax.spark:spark-cassandra-connector_2.12:3.3.0 --conf spark.sql.extensions=com.datastax.spark.connector.CassandraSparkExtensions

  spark-worker-1:
    image: bde2020/spark-worker:3.2.0-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    volumes:
      - ./driver:/spark/jars/driver/
    #command: ./spark/bin/pyspark --packages com.datastax.spark:spark-cassandra-connector_2.12:3.3.0 --conf spark.sql.extensions=com.datastax.spark.connector.CassandraSparkExtensions

  cassandra:
    image: cassandra:latest
    container_name: cassandra
    ports:
      - "9042:9042"
    environment:
      - "MAX_HEAP_SIZE=256M"
      - "HEAP_NEWSIZE=128M"
    restart: always
    volumes:
      - ./baza:/var/lib/cassandra
    healthcheck:
      test: [ "CMD", "cqlsh", "-u cassandra", "-p cassandra" ,"-e describe keyspaces" ]

  creater_env:
    depends_on:
      - cassandra
    build:
      context: ./work_baza

  app:
    depends_on:
      - creater_env
    build:
      context: ./code

